# ===== import å€åŸŸ =====
from flask import Flask, request, abort
import os
import time
import json
import math
import re
from collections import Counter
from openai import OpenAI

from linebot import LineBotApi, WebhookHandler
from linebot.exceptions import InvalidSignatureError
from linebot.models import MessageEvent, TextMessage, TextSendMessage
# ===== import å€åŸŸçµæŸ =====


# ===== å¤šèªç³»æ–‡å­—ï¼ˆå›ºå®šå­—ä¸²ï¼Œä¸äº¤çµ¦ GPTï¼‰=====
TEXTS = {
    "zh": {
        "intro": (
            "ä½ å¥½ï¼Œæˆ‘æ˜¯ã€å¾®è½‰äººè³‡AIåŠ©æ‰‹ã€‘ğŸ¤–\n\n"
            "ä½ å¯ä»¥ç›´æ¥è¼¸å…¥äººè³‡ç›¸é—œå•é¡Œï¼Œä¾‹å¦‚ï¼š\n"
            "ãƒ»ç—…å‡è¦å‰‡æ˜¯ä»€éº¼ï¼Ÿ\n"
            "ãƒ»åŠ ç­è²»å¦‚ä½•è¨ˆç®—ï¼Ÿ\n"
            "ãƒ»ç‰¹ä¼‘è¦å®šæœ‰å“ªäº›ï¼Ÿ\n"
        ),
        "prefix": "ğŸ“Œ æ ¹æ“š {month} çš„ {code} ç‰ˆæœ¬ã€Š{name}ã€‹å…§å®¹å›è¦†ï¼š\n\n",
        "fallback": "æ­¤å•é¡Œåœ¨ç›®å‰è¦ç« å¼•ç”¨å…§å®¹ä¸­æ‰¾ä¸åˆ°æ˜ç¢ºä¾æ“šï¼Œè«‹æ´½äººè³‡å°ˆå“¡ã€‚",
        "answer_label": "ã€HR AI åŠ©æ‰‹å›è¦†ã€‘\n\n",
        "disclaimer": (
            "\n\n-----\n"
            "âš ï¸æœ¬å›è¦†ç”±å¾®è½‰äººè³‡ AI åŠ©ç†ä¾æ“šç¾è¡Œå…§éƒ¨è¦ç« æ–‡ä»¶æ‘˜è¦æä¾›ï¼Œåƒ…ä¾›åƒè€ƒã€‚\n"
            "å¦‚æœ‰ç–‘æ…®æˆ–éœ€æ­£å¼èªå®šï¼Œè«‹æ´½äººè³‡å°ˆå“¡ä¸¦ä»¥å…¬å¸å…¬å‘Šç‚ºæº–ã€‚"
        ),
        "lang_rule": "è«‹ç”¨ç¹é«”ä¸­æ–‡å›è¦†ã€‚"
    },
    "en": {
        "intro": (
            "Hi, I'm the microSHIFT HR AI assistant ğŸ¤–\n\n"
            "You can ask HR-related questions, for example:\n"
            "â€¢ Sick leave policy\n"
            "â€¢ Overtime pay calculation\n"
            "â€¢ Annual leave rules\n"
        ),
        "prefix": "ğŸ“Œ Based on {month} version {code} â€œ{name}â€, reply:\n\n",
        "fallback": "I canâ€™t find a clear basis in the current HR policy excerpts. Please contact HR.",
        "answer_label": "ã€HR AI Assistantã€‘\n\n",
        "disclaimer": (
            "\n\nâ€”----\n"
            "âš ï¸This reply is generated by an HR AI assistant based on internal policy excerpts for reference only.\n"
            "For official confirmation, please contact HR and refer to company announcements."
        ),
        "lang_rule": "Please reply in English."
    },
    "vi": {
        "intro": (
            "Xin chÃ o, tÃ´i lÃ  trá»£ lÃ½ AI NhÃ¢n sá»± microSHIFT ğŸ¤–\n\n"
            "Báº¡n cÃ³ thá»ƒ há»i cÃ¡c cÃ¢u há»i liÃªn quan Ä‘áº¿n NhÃ¢n sá»±, vÃ­ dá»¥:\n"
            "â€¢ Quy Ä‘á»‹nh nghá»‰ á»‘m\n"
            "â€¢ CÃ¡ch tÃ­nh lÆ°Æ¡ng tÄƒng ca\n"
            "â€¢ Quy Ä‘á»‹nh nghá»‰ phÃ©p nÄƒm\n"
        ),
        "prefix": "ğŸ“Œ Dá»±a trÃªn phiÃªn báº£n {month} {code} â€œ{name}â€, tráº£ lá»i:\n\n",
        "fallback": "TÃ´i khÃ´ng tÃ¬m tháº¥y cÄƒn cá»© rÃµ rÃ ng trong trÃ­ch Ä‘oáº¡n quy Ä‘á»‹nh hiá»‡n táº¡i. Vui lÃ²ng liÃªn há»‡ NhÃ¢n sá»±.",
        "answer_label": "ã€Trá»£ lÃ½ AI NhÃ¢n sá»±ã€‘\n\n",
        "disclaimer": (
            "\n\nâ€”----\n"
            "âš ï¸CÃ¢u tráº£ lá»i nÃ y do trá»£ lÃ½ AI NhÃ¢n sá»± táº¡o dá»±a trÃªn trÃ­ch Ä‘oáº¡n quy Ä‘á»‹nh ná»™i bá»™ vÃ  chá»‰ mang tÃ­nh tham kháº£o.\n"
            "Äá»ƒ xÃ¡c nháº­n chÃ­nh thá»©c, vui lÃ²ng liÃªn há»‡ NhÃ¢n sá»± vÃ  theo thÃ´ng bÃ¡o cá»§a cÃ´ng ty."
        ),
        "lang_rule": "Vui lÃ²ng tráº£ lá»i báº±ng tiáº¿ng Viá»‡t."
    }
}


def detect_lang(text: str) -> str:
    """
    ç°¡æ˜“èªè¨€åˆ¤æ–·ï¼ˆä¸é¡å¤–å‘¼å« GPTï¼ŒçœéŒ¢ä¹Ÿæ›´ç©©ï¼‰ï¼š
    - æœ‰è¶Šå—æ–‡è®ŠéŸ³ç¬¦è™Ÿ â†’ vi
    - è‹±æ–‡å­—æ¯æ¯”ä¾‹é«˜ â†’ en
    - å…¶ä»– â†’ zh
    """
    t = (text or "").strip()
    if not t:
        return "zh"

    if re.search(r"[ÄƒÃ¢Ä‘ÃªÃ´Æ¡Æ°Ã¡Ã áº£Ã£áº¡áº¥áº§áº©áº«áº­áº¯áº±áº³áºµáº·Ã©Ã¨áº»áº½áº¹áº¿á»á»ƒá»…á»‡Ã­Ã¬á»‰Ä©á»‹Ã³Ã²á»Ãµá»á»‘á»“á»•á»—á»™á»›á»á»Ÿá»¡á»£ÃºÃ¹á»§Å©á»¥á»©á»«á»­á»¯á»±Ã½á»³á»·á»¹á»µ]", t, re.IGNORECASE):
        return "vi"

    letters = re.findall(r"[A-Za-z]", t)
    if len(letters) >= 6 and (len(letters) / max(len(t), 1)) > 0.25:
        return "en"

    return "zh"


# ===== HR Bot è¨­å®š =====
INTRO_COOLDOWN_SECONDS = 60 * 60 * 12  # 12 å°æ™‚
last_seen = {}  # æš«å­˜æ¯å€‹ LINE ä½¿ç”¨è€…çš„æœ€å¾Œäº’å‹•æ™‚é–“ï¼ˆæ³¨æ„ï¼šRender é‡å•Ÿæœƒæ¸…ç©ºï¼Œå±¬æ­£å¸¸ï¼‰
SIMILARITY_THRESHOLD = 0.28  # å¤ªå¸¸æ‹’ç­”å¯èª¿ä½ 0.24~0.26
TOP_K = 6  # æŠ“å›ä¾†çš„å¼•ç”¨æ®µè½æ•¸


# ===== å»ºç«‹ Flask / OpenAI / LINE ç‰©ä»¶ =====
app = Flask(__name__)
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
line_bot_api = LineBotApi(os.getenv("LINE_CHANNEL_ACCESS_TOKEN"))
handler = WebhookHandler(os.getenv("LINE_CHANNEL_SECRET"))


# ===== è®€å– HR KB Indexï¼ˆå•Ÿå‹•æ™‚è®€ä¸€æ¬¡ï¼‰=====
KB_INDEX_PATH = os.path.join(os.path.dirname(__file__), "hr_kb_index.json")
with open(KB_INDEX_PATH, "r", encoding="utf-8") as f:
    KB = json.load(f)

KB_ITEMS = KB.get("items", [])
# KB["policies"] å¯é¸ç”¨ï¼Œé€™è£¡ä¸ä¸€å®šè¦


# ===== å‘é‡ç›¸ä¼¼åº¦ =====
def cosine_sim(a, b):
    dot = 0.0
    na = 0.0
    nb = 0.0
    for x, y in zip(a, b):
        dot += x * y
        na += x * x
        nb += y * y
    if na == 0 or nb == 0:
        return 0.0
    return dot / (math.sqrt(na) * math.sqrt(nb))


def retrieve_chunks(query: str, top_k: int = TOP_K):
    q_emb = client.embeddings.create(
        model="text-embedding-3-small",
        input=query
    ).data[0].embedding

    scored = []
    for it in KB_ITEMS:
        emb = it.get("embedding")
        txt = (it.get("text") or "").strip()
        if not emb or not txt:
            continue
        s = cosine_sim(q_emb, emb)
        scored.append((s, it))

    scored.sort(key=lambda x: x[0], reverse=True)
    top = scored[:top_k]

    refs = []
    for s, it in top:
        refs.append({
            "score": float(s),
            "policy_month": it.get("policy_month", "æœªçŸ¥æœˆä»½"),
            "policy_code": it.get("policy_code", "æœªçŸ¥ç‰ˆæ¬¡"),
            "policy_name": it.get("policy_name", "æœªçŸ¥è¾¦æ³•"),
            "source_filename": it.get("source_filename", ""),
            "chunk_id": it.get("chunk_id", 0),
            "text": (it.get("text", "") or "").strip()
        })
    return refs


def pick_best_policy(refs):
    """
    ä»¥å¤šæ•¸æ±ºé¸æœ€åƒå“ªä¸€ä»½æ–‡ä»¶ï¼›å¹³æ‰‹å°±å–ç¬¬ä¸€å€‹ï¼ˆé€šå¸¸æ˜¯æœ€é«˜åˆ†ï¼‰
    """
    if not refs:
        return ("æœªçŸ¥æœˆä»½", "æœªçŸ¥ç‰ˆæ¬¡", "æœªçŸ¥è¾¦æ³•")
    keys = [(r["policy_month"], r["policy_code"], r["policy_name"]) for r in refs]
    c = Counter(keys)
    best_key, _ = c.most_common(1)[0]
    return best_key


# ===== callback Webhook æ¥æ”¶ =====
@app.route("/callback", methods=["POST"])
def callback():
    signature = request.headers.get("X-Line-Signature")
    body = request.get_data(as_text=True)

    try:
        handler.handle(body, signature)
    except InvalidSignatureError:
        abort(400)

    return "OK"


# ===== handlerï¼šHR + RAG + GPT =====
@handler.add(MessageEvent, message=TextMessage)
def handle_message(event):
    user_text = (event.message.text or "").strip()
    user_id = event.source.user_id

    # ---- èªè¨€åˆ¤æ–· ----
    lang = detect_lang(user_text)
    T = TEXTS.get(lang, TEXTS["zh"])

    # ---- intro é¡¯ç¤ºç¯€å¥ ----
    now = time.time()
    last = last_seen.get(user_id)
    should_show_intro = (last is None) or ((now - last) > INTRO_COOLDOWN_SECONDS)
    last_seen[user_id] = now

    # ---- RAG æª¢ç´¢ ----
    refs = retrieve_chunks(user_text, top_k=TOP_K)
    best_score = refs[0]["score"] if refs else 0.0

    # ç›¸ä¼¼åº¦ä¸è¶³ï¼šç›´æ¥æ‹’ç­”ï¼ˆé¿å…ã€Œæ³›å‹åŸºæ³•ã€æˆ–äº‚è£œï¼‰
    if best_score < SIMILARITY_THRESHOLD:
        core = T["fallback"]
        if should_show_intro:
            reply_text = f"{T['intro']}\n{core}{T['disclaimer']}"
        else:
            reply_text = f"{core}{T['disclaimer']}"

        line_bot_api.reply_message(
            event.reply_token,
            TextSendMessage(text=reply_text)
        )
        return

    # ---- ç‰ˆæœ¬å‰ç¶´ ----
    policy_month, policy_code, policy_name = pick_best_policy(refs)
    prefix = T["prefix"].format(month=policy_month, code=policy_code, name=policy_name)

    # ---- å¼•ç”¨å…§å®¹å€å¡Šï¼ˆåªçµ¦å¿…è¦ç‰‡æ®µï¼‰----
    context_block = "\n\n".join(
        [f"[{r['policy_code']}#{r['chunk_id']}] {r['text']}" for r in refs]
    )

    # ---- GPT Promptï¼šå¼·åˆ¶åªä¾å¼•ç”¨å…§å®¹ + æŒ‡å®šå›è¦†èªè¨€ ----
    prompt = f"""
ä½ æ˜¯ microSHIFT å…¬å¸çš„ HR äººè³‡åŠ©ç†ã€‚

ã€è¦å‰‡ï¼ˆéå¸¸é‡è¦ï¼‰ã€‘
1) ä½ åªèƒ½æ ¹æ“šä¸‹æ–¹ã€å¼•ç”¨å…§å®¹ã€‘å›ç­”ï¼Œç¦æ­¢ä½¿ç”¨ä¸€èˆ¬å¸¸è­˜ã€ç¶²è·¯è³‡è¨Šæˆ–æ¨æ¸¬è£œå……ã€‚
2) å¦‚æœã€å¼•ç”¨å…§å®¹ã€‘ä¸è¶³ä»¥å›ç­”ï¼Œè«‹åªå›è¦†ä¸‹åˆ—å¥å­ï¼ˆä¸è¦åŠ ä»»ä½•è£œå……ï¼‰ï¼š
ã€Œ{T['fallback']}ã€

ã€èªè¨€è¦æ±‚ã€‘
{T['lang_rule']}

ã€å¼•ç”¨å…§å®¹ã€‘
{context_block}

ã€å“¡å·¥å•é¡Œã€‘
{user_text}

ã€å›ç­”æ ¼å¼è¦æ±‚ã€‘
- å°ˆæ¥­ã€æ¸…æ¥šã€ç°¡çŸ­
- å„ªå…ˆç”¨æ¢åˆ—
- è‹¥æœ‰æ¢ä»¶/ä¾‹å¤–ï¼Œéœ€è¬›æ¸…æ¥š
"""

    resp = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": "ä½ æ˜¯å…¬å¸å…§éƒ¨ HR Botï¼ˆåªèƒ½ä¾å¼•ç”¨å…§å®¹å›ç­”ï¼‰"},
            {"role": "user", "content": prompt}
        ],
        temperature=0.1
    )

    gpt_answer = (resp.choices[0].message.content or "").strip()

    # ---- çµ„åˆå›è¦†ï¼ˆå…è²¬è²æ˜å›ºå®šåŠ åœ¨æœ€å¾Œï¼Œä¸äº¤çµ¦ GPTï¼‰----
    if should_show_intro:
        reply_text = f"{T['intro']}\n{prefix}{T['answer_label']}{gpt_answer}{T['disclaimer']}"
    else:
        reply_text = f"{prefix}{T['answer_label']}{gpt_answer}{T['disclaimer']}"

    line_bot_api.reply_message(
        event.reply_token,
        TextSendMessage(text=reply_text)
    )


if __name__ == "__main__":
    port = int(os.environ.get("PORT", 10000))
    app.run(host="0.0.0.0", port=port)
