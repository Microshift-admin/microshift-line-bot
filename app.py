# ===== import å€åŸŸ =====
from flask import Flask, request, abort
import os
import time
import json
import math
import re
from collections import Counter
from openai import OpenAI

from linebot import LineBotApi, WebhookHandler
from linebot.exceptions import InvalidSignatureError
from linebot.models import MessageEvent, TextMessage, TextSendMessage
# ===== import å€åŸŸçµæŸ =====


# ===== å¤šèªç³»æ–‡å­—ï¼ˆå›ºå®šå­—ä¸²ï¼Œä¸äº¤çµ¦ GPTï¼‰=====
TEXTS = {
    "zh": {
        "intro": (
            "ä½ å¥½ï¼Œæˆ‘æ˜¯ã€å¾®è½‰äººè³‡AIåŠ©æ‰‹ã€‘ğŸ¤–\n\n"
            "ä½ å¯ä»¥ç›´æ¥è¼¸å…¥äººè³‡ç›¸é—œå•é¡Œï¼Œä¾‹å¦‚ï¼š\n"
            "ãƒ»ç—…å‡è¦å‰‡æ˜¯ä»€éº¼ï¼Ÿ\n"
            "ãƒ»åŠ ç­è²»å¦‚ä½•è¨ˆç®—ï¼Ÿ\n"
            "ãƒ»ç‰¹ä¼‘è¦å®šæœ‰å“ªäº›ï¼Ÿ\n"
        ),
        "fallback": "æ­¤å•é¡Œåœ¨ç›®å‰è¦ç« å¼•ç”¨å…§å®¹ä¸­æ‰¾ä¸åˆ°æ˜ç¢ºä¾æ“šï¼Œè«‹æ´½äººè³‡å°ˆå“¡ã€‚",
        "answer_label": "ã€HR AI åŠ©æ‰‹å›è¦†ã€‘\n\n",
        "disclaimer": (
            "\n\n-----\n"
            "âš ï¸æœ¬å›è¦†ç”±å¾®è½‰äººè³‡ AI åŠ©ç†ä¾æ“šç¾è¡Œå…§éƒ¨è¦ç« æ–‡ä»¶æ‘˜è¦æä¾›ï¼Œåƒ…ä¾›åƒè€ƒã€‚\n"
            "å¦‚æœ‰ç–‘æ…®æˆ–éœ€æ­£å¼èªå®šï¼Œè«‹æ´½äººè³‡å°ˆå“¡ä¸¦ä»¥å…¬å¸å…¬å‘Šç‚ºæº–ã€‚"
        ),
        "lang_rule": "è«‹ç”¨ç¹é«”ä¸­æ–‡å›è¦†ã€‚",
        "prefix_main": "ğŸ“Œ ä¸»è¦ä¾æ“šï¼š{month} çš„ {code} ç‰ˆæœ¬ã€Š{name}ã€‹\n",
        "prefix_others": "ğŸ“ å¦åƒè€ƒï¼š{others}\n\n",
    },
    "en": {
        "intro": (
            "Hi, I'm the microSHIFT HR AI assistant ğŸ¤–\n\n"
            "You can ask HR-related questions, for example:\n"
            "â€¢ Sick leave policy\n"
            "â€¢ Overtime pay calculation\n"
            "â€¢ Annual leave rules\n"
        ),
        "fallback": "I canâ€™t find a clear basis in the current HR policy excerpts. Please contact HR.",
        "answer_label": "ã€HR AI Assistantã€‘\n\n",
        "disclaimer": (
            "\n\nâ€”----\n"
            "âš ï¸This reply is generated by an HR AI assistant based on internal policy excerpts for reference only.\n"
            "For official confirmation, please contact HR and refer to company announcements."
        ),
        "lang_rule": "Please reply in English.",
        "prefix_main": "ğŸ“Œ Primary source: {month} version {code} â€œ{name}â€\n",
        "prefix_others": "ğŸ“ Additional references: {others}\n\n",
    },
    "vi": {
        "intro": (
            "Xin chÃ o, tÃ´i lÃ  trá»£ lÃ½ AI NhÃ¢n sá»± microSHIFT ğŸ¤–\n\n"
            "Báº¡n cÃ³ thá»ƒ há»i cÃ¡c cÃ¢u há»i liÃªn quan Ä‘áº¿n NhÃ¢n sá»±, vÃ­ dá»¥:\n"
            "â€¢ Quy Ä‘á»‹nh nghá»‰ á»‘m\n"
            "â€¢ CÃ¡ch tÃ­nh lÆ°Æ¡ng tÄƒng ca\n"
            "â€¢ Quy Ä‘á»‹nh nghá»‰ phÃ©p nÄƒm\n"
        ),
        "fallback": "TÃ´i khÃ´ng tÃ¬m tháº¥y cÄƒn cá»© rÃµ rÃ ng trong trÃ­ch Ä‘oáº¡n quy Ä‘á»‹nh hiá»‡n táº¡i. Vui lÃ²ng liÃªn há»‡ NhÃ¢n sá»±.",
        "answer_label": "ã€Trá»£ lÃ½ AI NhÃ¢n sá»±ã€‘\n\n",
        "disclaimer": (
            "\n\n-----\n"
            "âš ï¸ CÃ¢u tráº£ lá»i nÃ y do trá»£ lÃ½ AI NhÃ¢n sá»± táº¡o dá»±a trÃªn trÃ­ch Ä‘oáº¡n quy Ä‘á»‹nh ná»™i bá»™ vÃ  chá»‰ mang tÃ­nh tham kháº£o.\n"
            "Äá»ƒ xÃ¡c nháº­n chÃ­nh thá»©c, vui lÃ²ng liÃªn há»‡ NhÃ¢n sá»± vÃ  theo thÃ´ng bÃ¡o cá»§a cÃ´ng ty."
        ),
        "lang_rule": "Vui lÃ²ng tráº£ lá»i báº±ng tiáº¿ng Viá»‡t.",
        "prefix_main": "ğŸ“Œ Nguá»“n chÃ­nh: phiÃªn báº£n {month} {code} â€œ{name}â€\n",
        "prefix_others": "ğŸ“ Tham kháº£o thÃªm: {others}\n\n",
    }
}


def detect_lang(text: str) -> str:
    """
    ç°¡æ˜“èªè¨€åˆ¤æ–·ï¼ˆä¸é¡å¤–å‘¼å« GPTï¼ŒçœéŒ¢ä¹Ÿæ›´ç©©ï¼‰ï¼š
    - æœ‰è¶Šå—æ–‡è®ŠéŸ³ç¬¦è™Ÿ â†’ vi
    - è‹±æ–‡å­—æ¯æ¯”ä¾‹é«˜ â†’ en
    - å…¶ä»– â†’ zh
    """
    t = (text or "").strip()
    if not t:
        return "zh"

    if re.search(r"[ÄƒÃ¢Ä‘ÃªÃ´Æ¡Æ°Ã¡Ã áº£Ã£áº¡áº¥áº§áº©áº«áº­áº¯áº±áº³áºµáº·Ã©Ã¨áº»áº½áº¹áº¿á»á»ƒá»…á»‡Ã­Ã¬á»‰Ä©á»‹Ã³Ã²á»Ãµá»á»‘á»“á»•á»—á»™á»›á»á»Ÿá»¡á»£ÃºÃ¹á»§Å©á»¥á»©á»«á»­á»¯á»±Ã½á»³á»·á»¹á»µ]", t, re.IGNORECASE):
        return "vi"

    letters = re.findall(r"[A-Za-z]", t)
    if len(letters) >= 6 and (len(letters) / max(len(t), 1)) > 0.25:
        return "en"

    return "zh"


# ===== HR Bot è¨­å®š =====
INTRO_COOLDOWN_SECONDS = 60 * 60 * 12  # 12 å°æ™‚
last_seen = {}  # æš«å­˜æ¯å€‹ LINE ä½¿ç”¨è€…çš„æœ€å¾Œäº’å‹•æ™‚é–“ï¼ˆRender é‡å•Ÿæœƒæ¸…ç©ºï¼Œå±¬æ­£å¸¸ï¼‰
SIMILARITY_THRESHOLD = 0.28  # å¤ªå¸¸æ‹’ç­”å¯èª¿ä½ 0.24~0.26
TOP_K = 6  # æŠ“å›ä¾†çš„å¼•ç”¨æ®µè½æ•¸


# ===== å»ºç«‹ Flask / OpenAI / LINE ç‰©ä»¶ =====
app = Flask(__name__)
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
line_bot_api = LineBotApi(os.getenv("LINE_CHANNEL_ACCESS_TOKEN"))
handler = WebhookHandler(os.getenv("LINE_CHANNEL_SECRET"))


# ===== è®€å– HR KB Indexï¼ˆå•Ÿå‹•æ™‚è®€ä¸€æ¬¡ï¼‰=====
KB_INDEX_PATH = os.path.join(os.path.dirname(__file__), "hr_kb_index.json")
with open(KB_INDEX_PATH, "r", encoding="utf-8") as f:
    KB = json.load(f)

KB_ITEMS = KB.get("items", [])


# ===== å‘é‡ç›¸ä¼¼åº¦ =====
def cosine_sim(a, b):
    dot = 0.0
    na = 0.0
    nb = 0.0
    for x, y in zip(a, b):
        dot += x * y
        na += x * x
        nb += y * y
    if na == 0 or nb == 0:
        return 0.0
    return dot / (math.sqrt(na) * math.sqrt(nb))


def retrieve_chunks(query: str, top_k: int = TOP_K):
    q_emb = client.embeddings.create(
        model="text-embedding-3-small",
        input=query
    ).data[0].embedding

    scored = []
    for it in KB_ITEMS:
        emb = it.get("embedding")
        txt = (it.get("text") or "").strip()
        if not emb or not txt:
            continue
        s = cosine_sim(q_emb, emb)
        scored.append((s, it))

    scored.sort(key=lambda x: x[0], reverse=True)
    top = scored[:top_k]

    refs = []
    for s, it in top:
        refs.append({
            "score": float(s),
            "policy_month": it.get("policy_month", "æœªçŸ¥æœˆä»½"),
            "policy_code": it.get("policy_code", "æœªçŸ¥ç‰ˆæ¬¡"),
            "policy_name": it.get("policy_name", "æœªçŸ¥è¾¦æ³•"),
            "source_filename": it.get("source_filename", ""),
            "chunk_id": it.get("chunk_id", 0),
            "text": (it.get("text", "") or "").strip()
        })
    return refs


def collect_policies_in_order(refs):
    """
    ä¾ç…§ refsï¼ˆç›¸ä¼¼åº¦ç”±é«˜åˆ°ä½ï¼‰æ”¶é›†ä¸é‡è¤‡çš„è¦ç« æ¸…å–®
    å›å‚³ï¼š[(month, code, name), ...]ï¼Œç¬¬ä¸€å€‹è¦–ç‚ºä¸»è¦ä¾æ“š
    """
    seen = set()
    policies = []
    for r in refs:
        key = (r.get("policy_month"), r.get("policy_code"), r.get("policy_name"))
        if key in seen:
            continue
        seen.add(key)
        policies.append(key)
    return policies


def build_multi_source_prefix(T, refs):
    """
    ç”¢ç”Ÿå¤šä¾†æºå‰ç¶´ï¼š
    - ä¸»è¦ä¾æ“šï¼šrefs ä¸­æœ€é«˜åˆ†é‚£æ‰¹æ‰€å±¬è¦ç« ï¼ˆç¬¬ä¸€å€‹ï¼‰
    - å¦åƒè€ƒï¼šåŒä¸€æ¬¡æª¢ç´¢ä¸­å‡ºç¾çš„å…¶ä»–è¦ç« ï¼ˆå»é‡ï¼‰
    """
    policies = collect_policies_in_order(refs)
    if not policies:
        return "\n"

    main_month, main_code, main_name = policies[0]
    prefix = T["prefix_main"].format(month=main_month, code=main_code, name=main_name)

    if len(policies) > 1:
        others = "ã€".join([f"{m} {c}ã€Š{n}ã€‹" if T is TEXTS["zh"] else f"{m} {c} â€œ{n}â€" for m, c, n in policies[1:]])
        prefix += T["prefix_others"].format(others=others)
    else:
        prefix += "\n"

    return prefix


# ===== callback Webhook æ¥æ”¶ =====
@app.route("/callback", methods=["POST"])
def callback():
    signature = request.headers.get("X-Line-Signature")
    body = request.get_data(as_text=True)

    try:
        handler.handle(body, signature)
    except InvalidSignatureError:
        abort(400)

    return "OK"


# ===== handlerï¼šHR + RAG + GPT =====
@handler.add(MessageEvent, message=TextMessage)
def handle_message(event):
    user_text = (event.message.text or "").strip()
    user_id = event.source.user_id

    # ---- èªè¨€åˆ¤æ–· ----
    lang = detect_lang(user_text)
    T = TEXTS.get(lang, TEXTS["zh"])

    # ---- intro é¡¯ç¤ºç¯€å¥ ----
    now = time.time()
    last = last_seen.get(user_id)
    should_show_intro = (last is None) or ((now - last) > INTRO_COOLDOWN_SECONDS)
    last_seen[user_id] = now

    # ---- RAG æª¢ç´¢ ----
    refs = retrieve_chunks(user_text, top_k=TOP_K)
    best_score = refs[0]["score"] if refs else 0.0

    # ç›¸ä¼¼åº¦ä¸è¶³ï¼šç›´æ¥æ‹’ç­”ï¼ˆé¿å…æ³›å›ç­”ï¼‰
    if best_score < SIMILARITY_THRESHOLD:
        core = T["fallback"]
        if should_show_intro:
            reply_text = f"{T['intro']}\n{core}{T['disclaimer']}"
        else:
            reply_text = f"{core}{T['disclaimer']}"

        line_bot_api.reply_message(
            event.reply_token,
            TextSendMessage(text=reply_text)
        )
        return

    # ---- å¤šä¾†æºå‰ç¶´ï¼ˆåªæ”¹é€™è£¡ï¼‰----
    prefix = build_multi_source_prefix(T, refs)

    # ---- å¼•ç”¨å…§å®¹å€å¡Šï¼ˆåªçµ¦å¿…è¦ç‰‡æ®µï¼‰----
    context_block = "\n\n".join(
        [f"[{r['policy_code']}#{r['chunk_id']}] {r['text']}" for r in refs]
    )

    # ---- GPT Promptï¼šç¶­æŒåŸæœ¬è¦å‰‡ï¼ˆä¸åŠ å…¥åˆ¶åº¦è§’è‰²è¦å‰‡ï¼‰----
    prompt = f"""
ä½ æ˜¯ microSHIFT å…¬å¸çš„ HR äººè³‡åŠ©ç†ã€‚

ã€è¦å‰‡ï¼ˆéå¸¸é‡è¦ï¼‰ã€‘
1) ä½ åªèƒ½æ ¹æ“šä¸‹æ–¹ã€å¼•ç”¨å…§å®¹ã€‘å›ç­”ï¼Œç¦æ­¢ä½¿ç”¨ä¸€èˆ¬å¸¸è­˜ã€ç¶²è·¯è³‡è¨Šæˆ–æ¨æ¸¬è£œå……ã€‚
2) å¦‚æœã€å¼•ç”¨å…§å®¹ã€‘ä¸è¶³ä»¥å›ç­”ï¼Œè«‹åªå›è¦†ä¸‹åˆ—å¥å­ï¼ˆä¸è¦åŠ ä»»ä½•è£œå……ï¼‰ï¼š
ã€Œ{T['fallback']}ã€

ã€èªè¨€è¦æ±‚ã€‘
{T['lang_rule']}

ã€å¼•ç”¨å…§å®¹ã€‘
{context_block}

ã€å“¡å·¥å•é¡Œã€‘
{user_text}

ã€å›ç­”æ ¼å¼è¦æ±‚ã€‘
- å°ˆæ¥­ã€æ¸…æ¥šã€ç°¡çŸ­
- å„ªå…ˆç”¨æ¢åˆ—
- è‹¥æœ‰æ¢ä»¶/ä¾‹å¤–ï¼Œéœ€è¬›æ¸…æ¥š
"""

    resp = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": "ä½ æ˜¯å…¬å¸å…§éƒ¨ HR Botï¼ˆåªèƒ½ä¾å¼•ç”¨å…§å®¹å›ç­”ï¼‰"},
            {"role": "user", "content": prompt}
        ],
        temperature=0.1
    )

    gpt_answer = (resp.choices[0].message.content or "").strip()

    # ---- çµ„åˆå›è¦†ï¼ˆå…è²¬è²æ˜å›ºå®šåŠ åœ¨æœ€å¾Œï¼Œä¸äº¤çµ¦ GPTï¼‰----
    if should_show_intro:
        reply_text = f"{T['intro']}\n{prefix}{T['answer_label']}{gpt_answer}{T['disclaimer']}"
    else:
        reply_text = f"{prefix}{T['answer_label']}{gpt_answer}{T['disclaimer']}"

    line_bot_api.reply_message(
        event.reply_token,
        TextSendMessage(text=reply_text)
    )


if __name__ == "__main__":
    port = int(os.environ.get("PORT", 10000))
    app.run(host="0.0.0.0", port=port)
