from flask import Flask, request, abort
import os
import time
import json
import math
from openai import OpenAI
from linebot import LineBotApi, WebhookHandler
from linebot.exceptions import InvalidSignatureError
from linebot.models import MessageEvent, TextMessage, TextSendMessage

# ===== HR Bot è¨­å®š =====
HR_INTRO_TEXT = (
    "ä½ å¥½ï¼Œæˆ‘æ˜¯ã€å¾®è½‰äººè³‡AIåŠ©æ‰‹ã€‘ğŸ¤–\n\n"
    "ä½ å¯ä»¥ç›´æ¥è¼¸å…¥äººè³‡ç›¸é—œå•é¡Œï¼Œä¾‹å¦‚ï¼š\n"
    "ãƒ»ç—…å‡è¦å‰‡æ˜¯ä»€éº¼ï¼Ÿ\n"
    "ãƒ»åŠ ç­è²»å¦‚ä½•è¨ˆç®—ï¼Ÿ\n"
    "ãƒ»ç‰¹ä¼‘è¦å®šæœ‰å“ªäº›ï¼Ÿ\n"
)
INTRO_COOLDOWN_SECONDS = 60 * 60 * 12  # 12 å°æ™‚
last_seen = {}

# ===== å»ºç«‹ Flask / OpenAI / LINE ç‰©ä»¶ =====
app = Flask(__name__)
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
line_bot_api = LineBotApi(os.getenv("LINE_CHANNEL_ACCESS_TOKEN"))
handler = WebhookHandler(os.getenv("LINE_CHANNEL_SECRET"))

# ===== è¼‰å…¥ HR KBï¼ˆåœ¨å•Ÿå‹•æ™‚è®€ä¸€æ¬¡ï¼‰=====
KB_PATH = os.path.join(os.path.dirname(__file__), "hr_kb.json")
with open(KB_PATH, "r", encoding="utf-8") as f:
    KB = json.load(f)

KB_META = KB.get("meta", {})
KB_ITEMS = KB.get("items", [])

def cosine_sim(a, b):
    # a,b: list[float]
    dot = 0.0
    na = 0.0
    nb = 0.0
    for x, y in zip(a, b):
        dot += x * y
        na += x * x
        nb += y * y
    if na == 0 or nb == 0:
        return 0.0
    return dot / (math.sqrt(na) * math.sqrt(nb))

def retrieve_chunks(query: str, top_k: int = 5):
    # 1) query embedding
    q_emb = client.embeddings.create(
        model="text-embedding-3-small",
        input=query
    ).data[0].embedding

    # 2) compute similarity
    scored = []
    for it in KB_ITEMS:
        emb = it.get("embedding")
        txt = it.get("text", "")
        if not emb or not txt:
            continue
        s = cosine_sim(q_emb, emb)
        scored.append((s, it))

    scored.sort(key=lambda x: x[0], reverse=True)
    top = scored[:top_k]

    # 3) çµ„æˆå¼•ç”¨æ–‡å­—ï¼ˆå«é ç¢¼ï¼‰
    refs = []
    for s, it in top:
        refs.append({
            "score": float(s),
            "page": it.get("page"),
            "text": it.get("text", "").strip()
        })
    return refs

# ===== callback Webhook =====
@app.route("/callback", methods=["POST"])
def callback():
    signature = request.headers.get("X-Line-Signature")
    body = request.get_data(as_text=True)
    try:
        handler.handle(body, signature)
    except InvalidSignatureError:
        abort(400)
    return "OK"

# ===== handlerï¼šHR + RAG + GPT =====
@handler.add(MessageEvent, message=TextMessage)
def handle_message(event):
    user_text = event.message.text.strip()
    user_id = event.source.user_id

    now = time.time()
    last = last_seen.get(user_id)
    should_show_intro = (last is None) or ((now - last) > INTRO_COOLDOWN_SECONDS)
    last_seen[user_id] = now

    # å–å‡º KB metaï¼ˆä½ è¦çš„ã€Œæ ¹æ“š 202509 çš„ HR-103-04 ç‰ˆæœ¬å‡ºå‹¤ç®¡ç†è¾¦æ³•ã€ï¼‰
    policy_month = KB_META.get("policy_month", "æœªçŸ¥æœˆä»½")
    policy_code = KB_META.get("policy_code", "æœªçŸ¥ç‰ˆæ¬¡")
    policy_name = KB_META.get("policy_name", "æœªçŸ¥è¾¦æ³•")

    prefix = f"ğŸ“Œ æ ¹æ“š {policy_month} çš„ {policy_code} ç‰ˆæœ¬ã€Š{policy_name}ã€‹å…§å®¹å›è¦†ï¼š\n"

    # ===== RAGï¼šæ‰¾æœ€ç›¸é—œæ¢æ–‡æ®µè½ =====
    refs = retrieve_chunks(user_text, top_k=5)

    # å¯åŠ ä¸€é“ã€Œç›¸é—œæ€§é–€æª»ã€ï¼šå¤ªä¸ç›¸é—œå°±ç›´æ¥è«‹æ´½äººè³‡
    # ä½ å¯å…ˆç”¨ 0.25~0.35 ä¹‹é–“æ¸¬è©¦ï¼ˆä¾æ–‡ä»¶å“è³ªèª¿æ•´ï¼‰
    best_score = refs[0]["score"] if refs else 0.0
    if best_score < 0.25:
        gpt_answer = "æ­¤å•é¡Œåœ¨ç›®å‰ç®¡ç†è¾¦æ³•å¼•ç”¨å…§å®¹ä¸­æ‰¾ä¸åˆ°æ˜ç¢ºä¾æ“šï¼Œè«‹æ´½äººè³‡å°ˆå“¡ã€‚"
    else:
        # æŠŠå¼•ç”¨æ®µè½å¡é€² promptï¼ˆéå¸¸é‡è¦ï¼‰
        context_block = "\n\n".join(
            [f"[é  {r['page']}] {r['text']}" for r in refs]
        )

        prompt = f"""
ä½ æ˜¯ microSHIFT å…¬å¸çš„ HR äººè³‡åŠ©ç†ã€‚
ä½ **åªèƒ½**ä¾æ“šã€Œå¼•ç”¨å…§å®¹ã€å›ç­”ï¼Œä¸å¾—ä½¿ç”¨ä¸€èˆ¬å¸¸è­˜æˆ–ç¶²è·¯è³‡è¨Šè£œå……ã€‚
å¦‚æœå¼•ç”¨å…§å®¹ä¸è¶³ä»¥å›ç­”ï¼Œè«‹å›è¦†ï¼šã€Œæ­¤å•é¡Œåœ¨ç›®å‰ç®¡ç†è¾¦æ³•å¼•ç”¨å…§å®¹ä¸­æ‰¾ä¸åˆ°æ˜ç¢ºä¾æ“šï¼Œè«‹æ´½äººè³‡å°ˆå“¡ã€‚ã€

ã€å¼•ç”¨å…§å®¹ã€‘
{context_block}

ã€å“¡å·¥å•é¡Œã€‘
{user_text}

ã€å›ç­”è¦æ±‚ã€‘
- ç”¨å“¡å·¥å•é¡Œçš„èªè¨€å›è¦†
- æ¸…æ¥šã€ç°¡çŸ­ã€æ¢åˆ—å¼å„ªå…ˆ
- å¦‚æœ‰æ¢æ–‡æ¢ä»¶æˆ–ä¾‹å¤–ï¼Œè¦æ˜ç¢ºå¯«å‡º
"""

        resp = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "ä½ æ˜¯å…¬å¸å…§éƒ¨ HR Botï¼ˆåš´æ ¼å¼•ç”¨æ–‡ä»¶å›ç­”ï¼‰"},
                {"role": "user", "content": prompt},
            ],
            temperature=0.1,
        )
        gpt_answer = resp.choices[0].message.content.strip()

    # çµ„åˆå›è¦†
    if should_show_intro:
        reply_text = f"{HR_INTRO_TEXT}\n{prefix}{gpt_answer}"
    else:
        reply_text = f"{prefix}{gpt_answer}"

    line_bot_api.reply_message(
        event.reply_token,
        TextSendMessage(text=reply_text)
    )

if __name__ == "__main__":
    port = int(os.environ.get("PORT", 10000))
    app.run(host="0.0.0.0", port=port)
